{"cells":[{"cell_type":"markdown","source":["-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["## SparkML on Streaming Data"],"metadata":{}},{"cell_type":"markdown","source":["Let's take in the model we saved earlier, and apply it to some streaming data!"],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom_Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.pipeline import PipelineModel\n\nfileName = userhome + \"/tmp/DT_Pipeline\"\npipelineModel = PipelineModel.load(fileName)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["We can simulate streaming data.\n\nNOTE: You must specify a schema when creating a streaming source DataFrame."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nschema = StructType([\n  StructField(\"rating\",DoubleType()), \n  StructField(\"review\",StringType())])\n\nstreamingData = (spark\n                 .readStream\n                 .schema(schema)\n                 .option(\"maxFilesPerTrigger\", 1)\n                 .parquet(\"/mnt/training/movie-reviews/imdb/imdb_ratings_50k.parquet\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Why is this stream taking so long? What configuration should we set?"],"metadata":{}},{"cell_type":"code","source":["stream = (pipelineModel\n          .transform(streamingData)\n          .groupBy(\"label\", \"prediction\")\n          .count()\n          .sort(\"label\", \"prediction\"))\n\ndisplay(stream)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>label</th><th>prediction</th><th>count</th></tr></thead><tbody><tr><td>0.0</td><td>0.0</td><td>12876</td></tr><tr><td>0.0</td><td>1.0</td><td>12122</td></tr><tr><td>1.0</td><td>0.0</td><td>3047</td></tr><tr><td>1.0</td><td>1.0</td><td>21949</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>&apos;200&apos;\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Let's try this again"],"metadata":{}},{"cell_type":"code","source":["stream = (pipelineModel\n          .transform(streamingData)\n          .groupBy(\"label\", \"prediction\")\n          .count()\n          .sort(\"label\", \"prediction\"))\n\ndisplay(stream)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>label</th><th>prediction</th><th>count</th></tr></thead><tbody><tr><td>0.0</td><td>0.0</td><td>12876</td></tr><tr><td>0.0</td><td>1.0</td><td>12122</td></tr><tr><td>1.0</td><td>0.0</td><td>3047</td></tr><tr><td>1.0</td><td>1.0</td><td>21949</td></tr></tbody></table></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Let's save our results to a file."],"metadata":{}},{"cell_type":"code","source":["import re\n\nstreamingView = str(re.sub('\\W', '', username))\ncheckpointFile = userhome + \"/tmp/checkPoint\"\ndbutils.fs.rm(checkpointFile, True) # Clear out the checkpointing directory\n\n(stream\n .writeStream\n .format(\"memory\")\n .option(\"checkpointLocation\", checkpointFile)\n .outputMode(\"complete\")\n .queryName(streamingView)\n .start())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>&lt;pyspark.sql.streaming.StreamingQuery at 0x7f2dc5cabf28&gt;\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["display(sql(\"select * from \" + streamingView))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>label</th><th>prediction</th><th>count</th></tr></thead><tbody><tr><td>0.0</td><td>0.0</td><td>9615</td></tr><tr><td>0.0</td><td>1.0</td><td>9055</td></tr><tr><td>1.0</td><td>0.0</td><td>2304</td></tr><tr><td>1.0</td><td>1.0</td><td>16521</td></tr></tbody></table></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"06b SparkML NLP Streaming Inference","notebookId":2890652819224428},"nbformat":4,"nbformat_minor":0}
